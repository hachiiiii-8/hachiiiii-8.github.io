[
  {
    "objectID": "posts/index.html",
    "href": "posts/index.html",
    "title": "Blog",
    "section": "",
    "text": "Missing Semester 1: The Shell\n\n\n\n\n\n\nBlog\n\n\nMissing-Semester\n\n\n\n\n\n\nNov 23, 2024\n\n\nWu Hao\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Home",
      "Blog"
    ]
  },
  {
    "objectID": "posts2/index.html",
    "href": "posts2/index.html",
    "title": "Project",
    "section": "",
    "text": "Recognize Handwritten Digits by CNN\n\n\n\n\n\n\nProject\n\n\n\n\n\n\nNov 16, 2024\n\n\nWu Hao\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Home",
      "Project"
    ]
  },
  {
    "objectID": "posts1/index.html",
    "href": "posts1/index.html",
    "title": "Work Record",
    "section": "",
    "text": "Week1\n\n\n\n\n\n\nWeek Report\n\n\n\n\n\n\nNov 16, 2024\n\n\nWu Hao\n\n\n\n\n\n\n\nWeek2\n\n\n\n\n\n\nWeek Report\n\n\n\n\n\n\nNov 23, 2024\n\n\nWu Hao\n\n\n\n\n\n\n\nWeek3\n\n\n\n\n\n\nWeek Report\n\n\n\n\n\n\nDec 7, 2024\n\n\nWu Hao\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Home",
      "Work Record"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "hao",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This is the contents of the about page for my blog.",
    "crumbs": [
      "Home",
      "About"
    ]
  },
  {
    "objectID": "about.html#about-this-blog",
    "href": "about.html#about-this-blog",
    "title": "About",
    "section": "",
    "text": "This is the contents of the about page for my blog.",
    "crumbs": [
      "Home",
      "About"
    ]
  },
  {
    "objectID": "posts1/2024-11-16-worklog-post.html#the-birth-of-my-research-partner-lan",
    "href": "posts1/2024-11-16-worklog-post.html#the-birth-of-my-research-partner-lan",
    "title": "Week1",
    "section": "2. The Birth of My Research Partner LAN ðŸ¥³ ðŸ¥³",
    "text": "2. The Birth of My Research Partner LAN ðŸ¥³ ðŸ¥³",
    "crumbs": [
      "Home",
      "Work Record",
      "Week1"
    ]
  },
  {
    "objectID": "posts2/2024-11-16-Recognize-post.html",
    "href": "posts2/2024-11-16-Recognize-post.html",
    "title": "Recognize Handwritten Digits by CNN",
    "section": "",
    "text": "A Handwritten Digits Recognition Model based CNN.\n\nBasic Information\n\nNetwork: CNN\nDataset: MNIST\nFramework: Pytorch\nGPU: NVIDIA GTX1070\n\n\n\n\n\nYou can download data from MNIST\n\n\n\n\n\n\n\nCode\nimport cv2\nimport numpy as np\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nimport torch.nn as nn\nimport matplotlib.pyplot as plt\nfrom week_log_1.vgg import CNN\nimport sys\nimport time\nimport scipy.io as scio\nfrom IPython.display import Image, display\n\n\n\n\n\n\n\nCode\n# Reversing the black and white thresholds for each pixel\ndef accessPiexl(img):\n    height = img.shape[0]\n    width = img.shape[1]\n    for i in range(height):\n       for j in range(width):\n           img[i][j] = 255 - img[i][j]\n    return img\n\n# Inverse binarized image\ndef accessBinary(img, threshold=165):\n    img = accessPiexl(img)\n    kernel = np.ones((3, 3), np.uint8)\n    img = cv2.GaussianBlur(img, (3, 3), 0) #Gaussian filter\n    img = cv2.erode(img, kernel, iterations=1) #Border burr removal\n    # adaptive filter\n    img = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 7, -9)\n    img = cv2.dilate(img, kernel, iterations=1)\n    return img\n\n# For showing prediction results\ndef showResults(path, borders, results=None):\n    img = cv2.imread(path)\n    for i, border in enumerate(borders):\n        cv2.rectangle(img, border[0], border[1], (0, 0, 255))\n        if results:\n            cv2.putText(img, str(results[i]), border[0], cv2.FONT_HERSHEY_COMPLEX, 0.8, (0, 255, 0), 1)\n    cv2.waitKey(0)\n    cv2.imwrite('week_log_1/out.jpg',img)\n    display(Image(filename='week_log_1/out.jpg'))\n\n#Search the edge, and return the top right and bottom left coner of the digits\ndef findBorderContours(path, maxArea=1800):\n    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n    img = accessBinary(img)\n    contours, hierarchy = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n    borders = []\n    for contour in contours:\n        #creat a boder\n        x, y, w, h = cv2.boundingRect(contour)\n        if w*h &gt; maxArea:\n            #the coordinate of boder\n            border = [(x, y), (x+w, y+h)]\n            borders.append(border)\n    return borders\n\ndef transUSPS(path, borders, size=(28, 28)):\n    imgData = np.zeros((len(borders), size[0], size[0], 1), dtype='uint8')\n    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n    img = accessBinary(img)\n    for i, border in enumerate(borders):\n        borderImg = img[border[0][1]:border[1][1], border[0][0]:border[1][0]]\n        #Expand pixels based on maximum edge make the border close to square\n        extendPiexl = (max(borderImg.shape) - min(borderImg.shape)) // 2\n        #make border\n        targetImg = cv2.copyMakeBorder(borderImg, 7, 7, extendPiexl + 7, extendPiexl + 7, cv2.BORDER_CONSTANT)\n        targetImg = cv2.resize(targetImg, size)\n        # expand dimension\n        targetImg = np.expand_dims(targetImg, axis=-1)\n        imgData[i] = targetImg\n    return imgData\n# load the model and start predicting!\n\nprediction=[]\ndef predict(modelpath, imgData):\n    model = torch.load(modelpath,weights_only=False)\n    with torch.no_grad():\n        for i, data in enumerate(imgData):\n            data = data.type(torch.FloatTensor)\n            test_pred = model(data.cuda())\n            test_label = np.argmax(test_pred.cpu().data.numpy(), axis=1)\n            for y in test_label:\n                prediction.append(y)\n\n\n\n\n\n\n\nCode\nclass ImgDataset(Dataset):\n    def __init__(self, x, y=None, transform=None):\n        self.x = x\n        # label is required to be a LongTensor\n        self.y = y\n        if y is not None:\n            self.y = torch.LongTensor(y)\n        self.transform = transform\n    def __len__(self):\n        return len(self.x)\n    def __getitem__(self, index):\n        X = self.x[index]\n        if self.transform is not None:\n            X = self.transform(X)\n        if self.y is not None:\n            Y = self.y[index]\n            return X, Y\n        else:\n            return X\n\n\n\n\n\n\n\nCode\nclass Classifier(nn.Module):\n    def __init__(self):\n        super(Classifier, self).__init__()\n        # input dimension [1, 16, 16]\n        self.vgg = nn.Sequential(\n            nn.Conv2d(1, 16, 3, 1, 1),  # [16, 28, 28]\n            nn.BatchNorm2d(16),\n            nn.ReLU(),\n            nn.Conv2d(16, 32, 3, 1, 1),  # [32, 28, 28]\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2),  # [32, 14, 14]\n            nn.Conv2d(32, 64, 3, 1, 1),  # [64, 14, 14]\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.Conv2d(64, 128, 3, 1, 1),  # [128, 14, 14]\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2),  # [128, 7, 7]\n        )\n        #model definition\n        self.fc = nn.Sequential(\n            nn.Linear(128*7*7, 512),\n            nn.ReLU(),\n            nn.Dropout(p=0.5),\n            nn.Linear(512, 1024),\n            nn.ReLU(),\n            nn.Dropout(p=0.5),\n            nn.Linear(1024, 11),\n        )\n#forward propagation\n    def forward(self, x):\n        out = self.vgg(x)\n        out = out.view(out.size()[0], -1)\n        return self.fc(out)\n\n\n\n\n\n\n\nCode\nprint(\"Reading data\")\ndataFile2 = 'week_log_1/vgg/data/MNIST.mat'\ndata2 = scio.loadmat(dataFile2)\n\ntrain = data2['fea']\ntrain=train.reshape(70000,1,28,28)\nlabel = data2['gnd']\ntrain_x = train[:50000]\ntrain_y = label[:50000]\nprint(\"Size of training data = {}\".format(len(train_x)))\nval_x = train[50000:65000]\nval_y = label[50000:65000]\nprint(\"Size of validation data = {}\".format(len(val_x)))\ntest_x = train[65000:68000]\ntest_y = label[65000:68000]\ntest_y=test_y.reshape(3000)\nprint(\"Size of Testing data = {}\".format(len(test_x)))\nprint(\"reading over\")\n\n\nReading data\nSize of training data = 50000\nSize of validation data = 15000\nSize of Testing data = 3000\nreading over\n\n\n\n\n\n\n\nCode\nbatch_size = 500\nif sys.platform.startswith('win'):\n    num_workers = 0  \nelse:\n    num_workers = 4\ntrain_set = ImgDataset(train_x, train_y)\nval_set = ImgDataset(val_x, val_y)\ntrain_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=num_workers)\nval_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, shuffle=False,num_workers=num_workers)\n\ntrain_loss_list=[]\nval_loss_list = []\ntrain_acc_list = []\nval_acc_list = []\n\n#training\nmodel = CNN.Classifier().cuda()\nloss = nn.CrossEntropyLoss()  # loss: CrossEntropyLoss\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # Adam for optimizer\nnum_epoch = 25\nfor epoch in range(num_epoch):\n    epoch_start_time = time.time()\n    train_acc = 0.0\n    train_loss = 0.0\n    val_acc = 0.0\n    val_loss = 0.0\n    model.train()\n    for i, data in enumerate(train_loader):\n        data[0] = data[0].type(torch.FloatTensor)\n        data[1]=data[1].reshape(500)\n        optimizer.zero_grad()  \n        train_pred = model(data[0].cuda())  \n        batch_loss = loss(train_pred, data[1].cuda())  \n        batch_loss.backward()  \n        optimizer.step()  \n        train_acc += np.sum(np.argmax(train_pred.cpu().data.numpy(), axis=1) == data[1].numpy())\n        train_loss += batch_loss.item()\n    model.eval()\n\n    with torch.no_grad():\n        for i, data in enumerate(val_loader):\n            data[0] = data[0].type(torch.FloatTensor)\n            data[1] = data[1].reshape(500)\n            val_pred = model(data[0].cuda())\n            batch_loss = loss(val_pred, data[1].cuda())\n\n            val_acc += np.sum(np.argmax(val_pred.cpu().data.numpy(), axis=1) == data[1].numpy())\n            val_loss += batch_loss.item()\n        if epoch &gt; 20:\n            print('[%03d/%03d] %2.2f sec(s) Train Acc: %3.6f Loss: %3.6f | Val Acc: %3.6f loss: %3.6f' % \\\n              (epoch + 1, num_epoch, time.time() - epoch_start_time, \\\n               train_acc / train_set.__len__(), train_loss / train_set.__len__(), val_acc / val_set.__len__(),\n               val_loss / val_set.__len__()))\n        train_loss_list.append(train_loss / train_set.__len__())\n        val_loss_list.append(val_loss / val_set.__len__())\n        train_acc_list.append(train_acc / train_set.__len__())\n        val_acc_list.append(val_acc / val_set.__len__())\ntorch.save(model,'week_log_1/model.pt')\n\n\n[022/025] 1.42 sec(s) Train Acc: 0.995200 Loss: 0.000032 | Val Acc: 0.993400 loss: 0.000060\n[023/025] 1.43 sec(s) Train Acc: 0.996280 Loss: 0.000025 | Val Acc: 0.992200 loss: 0.000070\n[024/025] 1.43 sec(s) Train Acc: 0.996180 Loss: 0.000026 | Val Acc: 0.991933 loss: 0.000073\n[025/025] 1.42 sec(s) Train Acc: 0.995700 Loss: 0.000027 | Val Acc: 0.992600 loss: 0.000064\n\n\n\n\n\n\nCode\nplt.plot(np.arange(num_epoch),train_loss_list)\nplt.plot(np.arange(num_epoch),val_loss_list)\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.show()\n\nplt.plot(np.arange(num_epoch),train_acc_list)\nplt.plot(np.arange(num_epoch),val_acc_list)\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"accuracy\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\nFigureÂ 1: loss\n\n\n\n\n\n\n\n\n\n\n\nFigureÂ 2: accuracy\n\n\n\n\n\n\n\n\n\n\n\n\nCode\npath = 'week_log_1/vgg/data/2.jpg'\nmodel = 'week_log_1/model.pt'\nborders = findBorderContours(path)\n\nimgData = transUSPS(path, borders)\nimgData = np.transpose(imgData,[0,3,1,2])\nimgData = ImgDataset(imgData)\ntest_loader = DataLoader(imgData, batch_size=1, shuffle=False)\nresults = predict(model, test_loader)\nshowResults(path, borders, prediction)",
    "crumbs": [
      "Home",
      "Project",
      "Recognize Handwritten Digits by CNN"
    ]
  },
  {
    "objectID": "posts2/2024-11-16-Recognize-post.html#introduction",
    "href": "posts2/2024-11-16-Recognize-post.html#introduction",
    "title": "Recognize Handwritten Digits by CNN",
    "section": "",
    "text": "A Handwritten Digits Recognition Model based CNN.\n\nBasic Information\n\nNetwork: CNN\nDataset: MNIST\nFramework: Pytorch\nGPU: NVIDIA GTX1070",
    "crumbs": [
      "Home",
      "Project",
      "Recognize Handwritten Digits by CNN"
    ]
  },
  {
    "objectID": "posts2/2024-11-16-Recognize-post.html#download-data",
    "href": "posts2/2024-11-16-Recognize-post.html#download-data",
    "title": "Recognize Handwritten Digits by CNN",
    "section": "",
    "text": "You can download data from MNIST",
    "crumbs": [
      "Home",
      "Project",
      "Recognize Handwritten Digits by CNN"
    ]
  },
  {
    "objectID": "posts2/2024-11-16-Recognize-post.html#code",
    "href": "posts2/2024-11-16-Recognize-post.html#code",
    "title": "Recognize Handwritten Digits by CNN",
    "section": "",
    "text": "Code\nimport cv2\nimport numpy as np\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nimport torch.nn as nn\nimport matplotlib.pyplot as plt\nfrom week_log_1.vgg import CNN\nimport sys\nimport time\nimport scipy.io as scio\nfrom IPython.display import Image, display\n\n\n\n\n\n\n\nCode\n# Reversing the black and white thresholds for each pixel\ndef accessPiexl(img):\n    height = img.shape[0]\n    width = img.shape[1]\n    for i in range(height):\n       for j in range(width):\n           img[i][j] = 255 - img[i][j]\n    return img\n\n# Inverse binarized image\ndef accessBinary(img, threshold=165):\n    img = accessPiexl(img)\n    kernel = np.ones((3, 3), np.uint8)\n    img = cv2.GaussianBlur(img, (3, 3), 0) #Gaussian filter\n    img = cv2.erode(img, kernel, iterations=1) #Border burr removal\n    # adaptive filter\n    img = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 7, -9)\n    img = cv2.dilate(img, kernel, iterations=1)\n    return img\n\n# For showing prediction results\ndef showResults(path, borders, results=None):\n    img = cv2.imread(path)\n    for i, border in enumerate(borders):\n        cv2.rectangle(img, border[0], border[1], (0, 0, 255))\n        if results:\n            cv2.putText(img, str(results[i]), border[0], cv2.FONT_HERSHEY_COMPLEX, 0.8, (0, 255, 0), 1)\n    cv2.waitKey(0)\n    cv2.imwrite('week_log_1/out.jpg',img)\n    display(Image(filename='week_log_1/out.jpg'))\n\n#Search the edge, and return the top right and bottom left coner of the digits\ndef findBorderContours(path, maxArea=1800):\n    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n    img = accessBinary(img)\n    contours, hierarchy = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n    borders = []\n    for contour in contours:\n        #creat a boder\n        x, y, w, h = cv2.boundingRect(contour)\n        if w*h &gt; maxArea:\n            #the coordinate of boder\n            border = [(x, y), (x+w, y+h)]\n            borders.append(border)\n    return borders\n\ndef transUSPS(path, borders, size=(28, 28)):\n    imgData = np.zeros((len(borders), size[0], size[0], 1), dtype='uint8')\n    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n    img = accessBinary(img)\n    for i, border in enumerate(borders):\n        borderImg = img[border[0][1]:border[1][1], border[0][0]:border[1][0]]\n        #Expand pixels based on maximum edge make the border close to square\n        extendPiexl = (max(borderImg.shape) - min(borderImg.shape)) // 2\n        #make border\n        targetImg = cv2.copyMakeBorder(borderImg, 7, 7, extendPiexl + 7, extendPiexl + 7, cv2.BORDER_CONSTANT)\n        targetImg = cv2.resize(targetImg, size)\n        # expand dimension\n        targetImg = np.expand_dims(targetImg, axis=-1)\n        imgData[i] = targetImg\n    return imgData\n# load the model and start predicting!\n\nprediction=[]\ndef predict(modelpath, imgData):\n    model = torch.load(modelpath,weights_only=False)\n    with torch.no_grad():\n        for i, data in enumerate(imgData):\n            data = data.type(torch.FloatTensor)\n            test_pred = model(data.cuda())\n            test_label = np.argmax(test_pred.cpu().data.numpy(), axis=1)\n            for y in test_label:\n                prediction.append(y)\n\n\n\n\n\n\n\nCode\nclass ImgDataset(Dataset):\n    def __init__(self, x, y=None, transform=None):\n        self.x = x\n        # label is required to be a LongTensor\n        self.y = y\n        if y is not None:\n            self.y = torch.LongTensor(y)\n        self.transform = transform\n    def __len__(self):\n        return len(self.x)\n    def __getitem__(self, index):\n        X = self.x[index]\n        if self.transform is not None:\n            X = self.transform(X)\n        if self.y is not None:\n            Y = self.y[index]\n            return X, Y\n        else:\n            return X\n\n\n\n\n\n\n\nCode\nclass Classifier(nn.Module):\n    def __init__(self):\n        super(Classifier, self).__init__()\n        # input dimension [1, 16, 16]\n        self.vgg = nn.Sequential(\n            nn.Conv2d(1, 16, 3, 1, 1),  # [16, 28, 28]\n            nn.BatchNorm2d(16),\n            nn.ReLU(),\n            nn.Conv2d(16, 32, 3, 1, 1),  # [32, 28, 28]\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2),  # [32, 14, 14]\n            nn.Conv2d(32, 64, 3, 1, 1),  # [64, 14, 14]\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.Conv2d(64, 128, 3, 1, 1),  # [128, 14, 14]\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2),  # [128, 7, 7]\n        )\n        #model definition\n        self.fc = nn.Sequential(\n            nn.Linear(128*7*7, 512),\n            nn.ReLU(),\n            nn.Dropout(p=0.5),\n            nn.Linear(512, 1024),\n            nn.ReLU(),\n            nn.Dropout(p=0.5),\n            nn.Linear(1024, 11),\n        )\n#forward propagation\n    def forward(self, x):\n        out = self.vgg(x)\n        out = out.view(out.size()[0], -1)\n        return self.fc(out)\n\n\n\n\n\n\n\nCode\nprint(\"Reading data\")\ndataFile2 = 'week_log_1/vgg/data/MNIST.mat'\ndata2 = scio.loadmat(dataFile2)\n\ntrain = data2['fea']\ntrain=train.reshape(70000,1,28,28)\nlabel = data2['gnd']\ntrain_x = train[:50000]\ntrain_y = label[:50000]\nprint(\"Size of training data = {}\".format(len(train_x)))\nval_x = train[50000:65000]\nval_y = label[50000:65000]\nprint(\"Size of validation data = {}\".format(len(val_x)))\ntest_x = train[65000:68000]\ntest_y = label[65000:68000]\ntest_y=test_y.reshape(3000)\nprint(\"Size of Testing data = {}\".format(len(test_x)))\nprint(\"reading over\")\n\n\nReading data\nSize of training data = 50000\nSize of validation data = 15000\nSize of Testing data = 3000\nreading over\n\n\n\n\n\n\n\nCode\nbatch_size = 500\nif sys.platform.startswith('win'):\n    num_workers = 0  \nelse:\n    num_workers = 4\ntrain_set = ImgDataset(train_x, train_y)\nval_set = ImgDataset(val_x, val_y)\ntrain_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=num_workers)\nval_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, shuffle=False,num_workers=num_workers)\n\ntrain_loss_list=[]\nval_loss_list = []\ntrain_acc_list = []\nval_acc_list = []\n\n#training\nmodel = CNN.Classifier().cuda()\nloss = nn.CrossEntropyLoss()  # loss: CrossEntropyLoss\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # Adam for optimizer\nnum_epoch = 25\nfor epoch in range(num_epoch):\n    epoch_start_time = time.time()\n    train_acc = 0.0\n    train_loss = 0.0\n    val_acc = 0.0\n    val_loss = 0.0\n    model.train()\n    for i, data in enumerate(train_loader):\n        data[0] = data[0].type(torch.FloatTensor)\n        data[1]=data[1].reshape(500)\n        optimizer.zero_grad()  \n        train_pred = model(data[0].cuda())  \n        batch_loss = loss(train_pred, data[1].cuda())  \n        batch_loss.backward()  \n        optimizer.step()  \n        train_acc += np.sum(np.argmax(train_pred.cpu().data.numpy(), axis=1) == data[1].numpy())\n        train_loss += batch_loss.item()\n    model.eval()\n\n    with torch.no_grad():\n        for i, data in enumerate(val_loader):\n            data[0] = data[0].type(torch.FloatTensor)\n            data[1] = data[1].reshape(500)\n            val_pred = model(data[0].cuda())\n            batch_loss = loss(val_pred, data[1].cuda())\n\n            val_acc += np.sum(np.argmax(val_pred.cpu().data.numpy(), axis=1) == data[1].numpy())\n            val_loss += batch_loss.item()\n        if epoch &gt; 20:\n            print('[%03d/%03d] %2.2f sec(s) Train Acc: %3.6f Loss: %3.6f | Val Acc: %3.6f loss: %3.6f' % \\\n              (epoch + 1, num_epoch, time.time() - epoch_start_time, \\\n               train_acc / train_set.__len__(), train_loss / train_set.__len__(), val_acc / val_set.__len__(),\n               val_loss / val_set.__len__()))\n        train_loss_list.append(train_loss / train_set.__len__())\n        val_loss_list.append(val_loss / val_set.__len__())\n        train_acc_list.append(train_acc / train_set.__len__())\n        val_acc_list.append(val_acc / val_set.__len__())\ntorch.save(model,'week_log_1/model.pt')\n\n\n[022/025] 1.42 sec(s) Train Acc: 0.995200 Loss: 0.000032 | Val Acc: 0.993400 loss: 0.000060\n[023/025] 1.43 sec(s) Train Acc: 0.996280 Loss: 0.000025 | Val Acc: 0.992200 loss: 0.000070\n[024/025] 1.43 sec(s) Train Acc: 0.996180 Loss: 0.000026 | Val Acc: 0.991933 loss: 0.000073\n[025/025] 1.42 sec(s) Train Acc: 0.995700 Loss: 0.000027 | Val Acc: 0.992600 loss: 0.000064\n\n\n\n\n\n\nCode\nplt.plot(np.arange(num_epoch),train_loss_list)\nplt.plot(np.arange(num_epoch),val_loss_list)\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.show()\n\nplt.plot(np.arange(num_epoch),train_acc_list)\nplt.plot(np.arange(num_epoch),val_acc_list)\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"accuracy\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\nFigureÂ 1: loss\n\n\n\n\n\n\n\n\n\n\n\nFigureÂ 2: accuracy",
    "crumbs": [
      "Home",
      "Project",
      "Recognize Handwritten Digits by CNN"
    ]
  },
  {
    "objectID": "posts2/2024-11-16-Recognize-post.html#prediction-results",
    "href": "posts2/2024-11-16-Recognize-post.html#prediction-results",
    "title": "Recognize Handwritten Digits by CNN",
    "section": "",
    "text": "Code\npath = 'week_log_1/vgg/data/2.jpg'\nmodel = 'week_log_1/model.pt'\nborders = findBorderContours(path)\n\nimgData = transUSPS(path, borders)\nimgData = np.transpose(imgData,[0,3,1,2])\nimgData = ImgDataset(imgData)\ntest_loader = DataLoader(imgData, batch_size=1, shuffle=False)\nresults = predict(model, test_loader)\nshowResults(path, borders, prediction)",
    "crumbs": [
      "Home",
      "Project",
      "Recognize Handwritten Digits by CNN"
    ]
  },
  {
    "objectID": "posts/2024-11-23-Missing1-post.html",
    "href": "posts/2024-11-23-Missing1-post.html",
    "title": "Missing Semester 1: The Shell",
    "section": "",
    "text": "echo string: String/Variable output\nhao@DESKTOP-EUJ3G2G MINGW64 /e/blog\n$ echo \"hello\"\nhello\n\nhao@DESKTOP-EUJ3G2G MINGW64 /e/blog\n$ echo it is a test\nit is a test",
    "crumbs": [
      "Home",
      "Blog",
      "Missing Semester 1: The Shell"
    ]
  },
  {
    "objectID": "posts/2024-11-23-Missing1-post.html#echo",
    "href": "posts/2024-11-23-Missing1-post.html#echo",
    "title": "Missing Semester 1: The Shell",
    "section": "",
    "text": "echo string: String/Variable output\nhao@DESKTOP-EUJ3G2G MINGW64 /e/blog\n$ echo \"hello\"\nhello\n\nhao@DESKTOP-EUJ3G2G MINGW64 /e/blog\n$ echo it is a test\nit is a test",
    "crumbs": [
      "Home",
      "Blog",
      "Missing Semester 1: The Shell"
    ]
  },
  {
    "objectID": "posts/2024-11-23-Missing1-post.html#cd",
    "href": "posts/2024-11-23-Missing1-post.html#cd",
    "title": "Missing Semester 1: The Shell",
    "section": "cd and pwd",
    "text": "cd and pwd\npwd: display the current directory cd .: to the current directory cd ..: to its parent directory cd dir_name: to dir_name directory cd ~: to the home cd -: to the last visited directory\nhao@DESKTOP-EUJ3G2G MINGW64 /e/blog\n$ pwd\n/e/blog\n\nhao@DESKTOP-EUJ3G2G MINGW64 /\n$ cd /e/blog\nhao@DESKTOP-EUJ3G2G MINGW64 /e/blog\n\nhao@DESKTOP-EUJ3G2G MINGW64 /e/blog\n$ cd -\nhao@DESKTOP-EUJ3G2G MINGW64 /\n\nhao@DESKTOP-EUJ3G2G MINGW64 /\n$ cd ~\nhao@DESKTOP-EUJ3G2G MINGW64 ~",
    "crumbs": [
      "Home",
      "Blog",
      "Missing Semester 1: The Shell"
    ]
  },
  {
    "objectID": "posts/2024-11-23-Missing1-post.html#ls",
    "href": "posts/2024-11-23-Missing1-post.html#ls",
    "title": "Missing Semester 1: The Shell",
    "section": "ls",
    "text": "ls\nls: display all the content in the current directory ls -l: display the details of content\nhao@DESKTOP-EUJ3G2G MINGW64 /e/blog\n$ ls -l\ntotal 4\ndrwxr-xr-x 1 hao 197609 0 11æœˆ 20 23:26 _site/\ndrwxr-xr-x 1 hao 197609 0 11æœˆ 21 16:54 Missing_Semester/\ndrwxr-xr-x 1 hao 197609 0 11æœˆ 14 21:31 posts/\ndrwxr-xr-x 1 hao 197609 0 11æœˆ 21 16:49 WEEK_REPORT/\n\nd refers to a directory\nrwx: read, write, execute\nrwx refers to the owner of the fileâ€™s permissions\nr-x refers to the group of the fileâ€™s permissions\nr-x refers to anyone elseâ€™s permissions",
    "crumbs": [
      "Home",
      "Blog",
      "Missing Semester 1: The Shell"
    ]
  },
  {
    "objectID": "posts/2024-11-23-Missing1-post.html#dir",
    "href": "posts/2024-11-23-Missing1-post.html#dir",
    "title": "Missing Semester 1: The Shell",
    "section": "rmdir and mkdir",
    "text": "rmdir and mkdir\nrmdir dir_name : Delete empty dirs mkdir dir_name: Building a new directory\nhao@DESKTOP-EUJ3G2G MINGW64 /e/blog\n$ mkdir 1\nhao@DESKTOP-EUJ3G2G MINGW64 /e/blog\n$ ls\n_site/  1/  Missing_Semester/  posts/  WEEK_REPORT/\nhao@DESKTOP-EUJ3G2G MINGW64 /e/blog\n$ rmdir 1\nhao@DESKTOP-EUJ3G2G MINGW64 /e/blog\n$ ls\n_site/  Missing_Semester/  posts/  WEEK_REPORT/",
    "crumbs": [
      "Home",
      "Blog",
      "Missing Semester 1: The Shell"
    ]
  },
  {
    "objectID": "posts/2024-11-23-Missing1-post.html#cat",
    "href": "posts/2024-11-23-Missing1-post.html#cat",
    "title": "Missing Semester 1: The Shell",
    "section": "cat",
    "text": "cat\ncat file_nameandcat file1 file2: Displaying file contents cat file1 file2 &gt; combined_file: Redirecting files contents to other file cat &gt; newfile: Reading and saving content from the terminal cat &gt;&gt; existing_file: Appending content to an existing file\nhao@DESKTOP-EUJ3G2G MINGW64 /e/blog\n$ cat &gt; main1.py\nprint(\"hello\")\nhao@DESKTOP-EUJ3G2G MINGW64 /e/blog\n$ cat &gt; main2.py\nprint(\"hao\")\nhao@DESKTOP-EUJ3G2G MINGW64 /e/blog\n$ cat main1.py main2.py\nprint(\"hello\")\nprint(\"hao\")\nhao@DESKTOP-EUJ3G2G MINGW64 /e/blog\n$ cat main1.py main2.py &gt; main.py\nhao@DESKTOP-EUJ3G2G MINGW64 /e/blog\n$ python main.py\nhello\nhao",
    "crumbs": [
      "Home",
      "Blog",
      "Missing Semester 1: The Shell"
    ]
  },
  {
    "objectID": "posts/2024-11-23-Missing1-post.html#pipe",
    "href": "posts/2024-11-23-Missing1-post.html#pipe",
    "title": "Missing Semester 1: The Shell",
    "section": "pipe character",
    "text": "pipe character\n|: Using the output of one command as input to another command (Waiting for constructionâ€¦)",
    "crumbs": [
      "Home",
      "Blog",
      "Missing Semester 1: The Shell"
    ]
  },
  {
    "objectID": "posts/2024-11-23-Missing1-post.html#touch",
    "href": "posts/2024-11-23-Missing1-post.html#touch",
    "title": "Missing Semester 1: The Shell",
    "section": "touch",
    "text": "touch\ntouch file_name: Update the access and modification times of each FILE to the current time.",
    "crumbs": [
      "Home",
      "Blog",
      "Missing Semester 1: The Shell"
    ]
  }
]