[
  {
    "objectID": "posts/index.html",
    "href": "posts/index.html",
    "title": "Blog",
    "section": "",
    "text": "Missing Semester 2: Shell Tools and Scripting\n\n\n\nMissing-Semester\n\n\n\n\nWu Hao\n\n\nDec 12, 2024\n\n\n\n\n\n\n\n\n\n\n\nMissing Semester 1: The Shell\n\n\n\nMissing-Semester\n\n\n\n\nWu Hao\n\n\nNov 23, 2024\n\n\n\n\n\n\n\n\nNo matching items\n\n Back to top",
    "crumbs": [
      "Blog"
    ]
  },
  {
    "objectID": "posts/2024-11-23-Missing1-post.html",
    "href": "posts/2024-11-23-Missing1-post.html",
    "title": "Missing Semester 1: The Shell",
    "section": "",
    "text": "echo string: String/Variable output\n$ echo \"hello\"\nhello\n\n$ echo it is a test\nit is a test",
    "crumbs": [
      "Blog",
      "Missing-Semester",
      "The Shell"
    ]
  },
  {
    "objectID": "posts/2024-11-23-Missing1-post.html#echo",
    "href": "posts/2024-11-23-Missing1-post.html#echo",
    "title": "Missing Semester 1: The Shell",
    "section": "",
    "text": "echo string: String/Variable output\n$ echo \"hello\"\nhello\n\n$ echo it is a test\nit is a test",
    "crumbs": [
      "Blog",
      "Missing-Semester",
      "The Shell"
    ]
  },
  {
    "objectID": "posts/2024-11-23-Missing1-post.html#cd-and-pwd",
    "href": "posts/2024-11-23-Missing1-post.html#cd-and-pwd",
    "title": "Missing Semester 1: The Shell",
    "section": "cd and pwd",
    "text": "cd and pwd\npwd: display the current directory cd .: to the current directory cd ..: to its parent directory cd dir_name: to dir_name directory cd ~: to the home cd -: to the last visited directory\n$ cd /e/blog\n\n$ cd -\n/e/blog\n\n$ cd ~\n\n$ pwd\n/c/Users/hao",
    "crumbs": [
      "Blog",
      "Missing-Semester",
      "The Shell"
    ]
  },
  {
    "objectID": "posts/2024-11-23-Missing1-post.html#ls",
    "href": "posts/2024-11-23-Missing1-post.html#ls",
    "title": "Missing Semester 1: The Shell",
    "section": "ls",
    "text": "ls\nls: display all the content in the current directory ls -l: display the details of content\n$ ls -l\ntotal 4\ndrwxr-xr-x 1 hao 197609 0 11月 20 23:26 _site/\ndrwxr-xr-x 1 hao 197609 0 11月 21 16:54 Missing_Semester/\ndrwxr-xr-x 1 hao 197609 0 11月 14 21:31 posts/\ndrwxr-xr-x 1 hao 197609 0 11月 21 16:49 WEEK_REPORT/\n\nd refers to a directory\nrwx: read, write, execute\nrwx refers to the owner of the file’s permissions\nr-x refers to the group of the file’s permissions\nr-x refers to anyone else’s permissions",
    "crumbs": [
      "Blog",
      "Missing-Semester",
      "The Shell"
    ]
  },
  {
    "objectID": "posts/2024-11-23-Missing1-post.html#rmdir-and-mkdir",
    "href": "posts/2024-11-23-Missing1-post.html#rmdir-and-mkdir",
    "title": "Missing Semester 1: The Shell",
    "section": "rmdir and mkdir",
    "text": "rmdir and mkdir\nrmdir dir_name : Delete empty dirs mkdir dir_name: Building a new directory\n$ mkdir 1\n$ ls\n_site/  1/  Missing_Semester/  posts/  WEEK_REPORT/\n$ rmdir 1\n$ ls\n_site/  Missing_Semester/  posts/  WEEK_REPORT/",
    "crumbs": [
      "Blog",
      "Missing-Semester",
      "The Shell"
    ]
  },
  {
    "objectID": "posts/2024-11-23-Missing1-post.html#cat",
    "href": "posts/2024-11-23-Missing1-post.html#cat",
    "title": "Missing Semester 1: The Shell",
    "section": "cat",
    "text": "cat\ncat file_nameandcat file1 file2: Displaying file contents cat file1 file2 &gt; combined_file: Redirecting files contents to other file cat &gt; newfile: Reading and saving content from the terminal cat &gt;&gt; existing_file: Appending content to an existing file\n$ cat &gt; main1.py\nprint(\"hello\")\n$ cat &gt; main2.py\nprint(\"hao\")\n$ cat main1.py main2.py\nprint(\"hello\")\nprint(\"hao\")\n$ cat main1.py main2.py &gt; main.py\n$ python main.py\nhello\nhao",
    "crumbs": [
      "Blog",
      "Missing-Semester",
      "The Shell"
    ]
  },
  {
    "objectID": "posts/2024-11-23-Missing1-post.html#pipe-character",
    "href": "posts/2024-11-23-Missing1-post.html#pipe-character",
    "title": "Missing Semester 1: The Shell",
    "section": "pipe character",
    "text": "pipe character\n|: Using the output of one command as input to another command (Waiting for construction…)",
    "crumbs": [
      "Blog",
      "Missing-Semester",
      "The Shell"
    ]
  },
  {
    "objectID": "posts/2024-11-23-Missing1-post.html#touch",
    "href": "posts/2024-11-23-Missing1-post.html#touch",
    "title": "Missing Semester 1: The Shell",
    "section": "touch",
    "text": "touch\ntouch file_name: Update the access and modification times of each FILE to the current time.",
    "crumbs": [
      "Blog",
      "Missing-Semester",
      "The Shell"
    ]
  },
  {
    "objectID": "posts2/2024-11-16-Recognize-post.html",
    "href": "posts2/2024-11-16-Recognize-post.html",
    "title": "Recognize Handwritten Digits by CNN",
    "section": "",
    "text": "A Handwritten Digits Recognition Model based CNN.\n\nBasic Information\n\nNetwork: CNN\nDataset: MNIST\nFramework: Pytorch\nGPU: NVIDIA GTX1070\n\n\n\n\n\nYou can download data from MNIST\n\n\n\n\n\n\n\nCode\nimport cv2\nimport numpy as np\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nimport torch.nn as nn\nimport matplotlib.pyplot as plt\nfrom week_log_1.vgg import CNN\nimport sys\nimport time\nimport scipy.io as scio\nfrom IPython.display import Image, display\n\n\n\n\n\n\n\nCode\n# Reversing the black and white thresholds for each pixel\ndef accessPiexl(img):\n    height = img.shape[0]\n    width = img.shape[1]\n    for i in range(height):\n       for j in range(width):\n           img[i][j] = 255 - img[i][j]\n    return img\n\n# Inverse binarized image\ndef accessBinary(img, threshold=165):\n    img = accessPiexl(img)\n    kernel = np.ones((3, 3), np.uint8)\n    img = cv2.GaussianBlur(img, (3, 3), 0) #Gaussian filter\n    img = cv2.erode(img, kernel, iterations=1) #Border burr removal\n    # adaptive filter\n    img = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 7, -9)\n    img = cv2.dilate(img, kernel, iterations=1)\n    return img\n\n# For showing prediction results\ndef showResults(path, borders, results=None):\n    img = cv2.imread(path)\n    for i, border in enumerate(borders):\n        cv2.rectangle(img, border[0], border[1], (0, 0, 255))\n        if results:\n            cv2.putText(img, str(results[i]), border[0], cv2.FONT_HERSHEY_COMPLEX, 0.8, (0, 255, 0), 1)\n    cv2.waitKey(0)\n    cv2.imwrite('week_log_1/out.jpg',img)\n    display(Image(filename='week_log_1/out.jpg'))\n\n#Search the edge, and return the top right and bottom left coner of the digits\ndef findBorderContours(path, maxArea=1800):\n    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n    img = accessBinary(img)\n    contours, hierarchy = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n    borders = []\n    for contour in contours:\n        #creat a boder\n        x, y, w, h = cv2.boundingRect(contour)\n        if w*h &gt; maxArea:\n            #the coordinate of boder\n            border = [(x, y), (x+w, y+h)]\n            borders.append(border)\n    return borders\n\ndef transUSPS(path, borders, size=(28, 28)):\n    imgData = np.zeros((len(borders), size[0], size[0], 1), dtype='uint8')\n    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n    img = accessBinary(img)\n    for i, border in enumerate(borders):\n        borderImg = img[border[0][1]:border[1][1], border[0][0]:border[1][0]]\n        #Expand pixels based on maximum edge make the border close to square\n        extendPiexl = (max(borderImg.shape) - min(borderImg.shape)) // 2\n        #make border\n        targetImg = cv2.copyMakeBorder(borderImg, 7, 7, extendPiexl + 7, extendPiexl + 7, cv2.BORDER_CONSTANT)\n        targetImg = cv2.resize(targetImg, size)\n        # expand dimension\n        targetImg = np.expand_dims(targetImg, axis=-1)\n        imgData[i] = targetImg\n    return imgData\n# load the model and start predicting!\n\nprediction=[]\ndef predict(modelpath, imgData):\n    model = torch.load(modelpath,weights_only=False)\n    with torch.no_grad():\n        for i, data in enumerate(imgData):\n            data = data.type(torch.FloatTensor)\n            test_pred = model(data.cuda())\n            test_label = np.argmax(test_pred.cpu().data.numpy(), axis=1)\n            for y in test_label:\n                prediction.append(y)\n\n\n\n\n\n\n\nCode\nclass ImgDataset(Dataset):\n    def __init__(self, x, y=None, transform=None):\n        self.x = x\n        # label is required to be a LongTensor\n        self.y = y\n        if y is not None:\n            self.y = torch.LongTensor(y)\n        self.transform = transform\n    def __len__(self):\n        return len(self.x)\n    def __getitem__(self, index):\n        X = self.x[index]\n        if self.transform is not None:\n            X = self.transform(X)\n        if self.y is not None:\n            Y = self.y[index]\n            return X, Y\n        else:\n            return X\n\n\n\n\n\n\n\nCode\nclass Classifier(nn.Module):\n    def __init__(self):\n        super(Classifier, self).__init__()\n        # input dimension [1, 16, 16]\n        self.vgg = nn.Sequential(\n            nn.Conv2d(1, 16, 3, 1, 1),  # [16, 28, 28]\n            nn.BatchNorm2d(16),\n            nn.ReLU(),\n            nn.Conv2d(16, 32, 3, 1, 1),  # [32, 28, 28]\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2),  # [32, 14, 14]\n            nn.Conv2d(32, 64, 3, 1, 1),  # [64, 14, 14]\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.Conv2d(64, 128, 3, 1, 1),  # [128, 14, 14]\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2),  # [128, 7, 7]\n        )\n        #model definition\n        self.fc = nn.Sequential(\n            nn.Linear(128*7*7, 512),\n            nn.ReLU(),\n            nn.Dropout(p=0.5),\n            nn.Linear(512, 1024),\n            nn.ReLU(),\n            nn.Dropout(p=0.5),\n            nn.Linear(1024, 11),\n        )\n#forward propagation\n    def forward(self, x):\n        out = self.vgg(x)\n        out = out.view(out.size()[0], -1)\n        return self.fc(out)\n\n\n\n\n\n\n\nCode\nprint(\"Reading data\")\ndataFile2 = 'week_log_1/vgg/data/MNIST.mat'\ndata2 = scio.loadmat(dataFile2)\n\ntrain = data2['fea']\ntrain=train.reshape(70000,1,28,28)\nlabel = data2['gnd']\ntrain_x = train[:50000]\ntrain_y = label[:50000]\nprint(\"Size of training data = {}\".format(len(train_x)))\nval_x = train[50000:65000]\nval_y = label[50000:65000]\nprint(\"Size of validation data = {}\".format(len(val_x)))\ntest_x = train[65000:68000]\ntest_y = label[65000:68000]\ntest_y=test_y.reshape(3000)\nprint(\"Size of Testing data = {}\".format(len(test_x)))\nprint(\"reading over\")\n\n\nReading data\nSize of training data = 50000\nSize of validation data = 15000\nSize of Testing data = 3000\nreading over\n\n\n\n\n\n\n\nCode\nbatch_size = 500\nif sys.platform.startswith('win'):\n    num_workers = 0  \nelse:\n    num_workers = 4\ntrain_set = ImgDataset(train_x, train_y)\nval_set = ImgDataset(val_x, val_y)\ntrain_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=num_workers)\nval_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, shuffle=False,num_workers=num_workers)\n\ntrain_loss_list=[]\nval_loss_list = []\ntrain_acc_list = []\nval_acc_list = []\n\n#training\nmodel = CNN.Classifier().cuda()\nloss = nn.CrossEntropyLoss()  # loss: CrossEntropyLoss\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # Adam for optimizer\nnum_epoch = 25\nfor epoch in range(num_epoch):\n    epoch_start_time = time.time()\n    train_acc = 0.0\n    train_loss = 0.0\n    val_acc = 0.0\n    val_loss = 0.0\n    model.train()\n    for i, data in enumerate(train_loader):\n        data[0] = data[0].type(torch.FloatTensor)\n        data[1]=data[1].reshape(500)\n        optimizer.zero_grad()  \n        train_pred = model(data[0].cuda())  \n        batch_loss = loss(train_pred, data[1].cuda())  \n        batch_loss.backward()  \n        optimizer.step()  \n        train_acc += np.sum(np.argmax(train_pred.cpu().data.numpy(), axis=1) == data[1].numpy())\n        train_loss += batch_loss.item()\n    model.eval()\n\n    with torch.no_grad():\n        for i, data in enumerate(val_loader):\n            data[0] = data[0].type(torch.FloatTensor)\n            data[1] = data[1].reshape(500)\n            val_pred = model(data[0].cuda())\n            batch_loss = loss(val_pred, data[1].cuda())\n\n            val_acc += np.sum(np.argmax(val_pred.cpu().data.numpy(), axis=1) == data[1].numpy())\n            val_loss += batch_loss.item()\n        if epoch &gt; 20:\n            print('[%03d/%03d] %2.2f sec(s) Train Acc: %3.6f Loss: %3.6f | Val Acc: %3.6f loss: %3.6f' % \\\n              (epoch + 1, num_epoch, time.time() - epoch_start_time, \\\n               train_acc / train_set.__len__(), train_loss / train_set.__len__(), val_acc / val_set.__len__(),\n               val_loss / val_set.__len__()))\n        train_loss_list.append(train_loss / train_set.__len__())\n        val_loss_list.append(val_loss / val_set.__len__())\n        train_acc_list.append(train_acc / train_set.__len__())\n        val_acc_list.append(val_acc / val_set.__len__())\ntorch.save(model,'week_log_1/model.pt')\n\n\n[022/025] 1.42 sec(s) Train Acc: 0.994900 Loss: 0.000032 | Val Acc: 0.992200 loss: 0.000070\n[023/025] 1.42 sec(s) Train Acc: 0.995180 Loss: 0.000032 | Val Acc: 0.991667 loss: 0.000065\n[024/025] 1.42 sec(s) Train Acc: 0.996020 Loss: 0.000028 | Val Acc: 0.991333 loss: 0.000070\n[025/025] 1.43 sec(s) Train Acc: 0.995480 Loss: 0.000030 | Val Acc: 0.990800 loss: 0.000087\n\n\n\n\n\n\nCode\nplt.plot(np.arange(num_epoch),train_loss_list)\nplt.plot(np.arange(num_epoch),val_loss_list)\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.show()\n\nplt.plot(np.arange(num_epoch),train_acc_list)\nplt.plot(np.arange(num_epoch),val_acc_list)\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"accuracy\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\nFigure 1: loss\n\n\n\n\n\n\n\n\n\n\n\nFigure 2: accuracy\n\n\n\n\n\n\n\n\n\n\n\n\nCode\npath = 'week_log_1/vgg/data/2.jpg'\nmodel = 'week_log_1/model.pt'\nborders = findBorderContours(path)\n\nimgData = transUSPS(path, borders)\nimgData = np.transpose(imgData,[0,3,1,2])\nimgData = ImgDataset(imgData)\ntest_loader = DataLoader(imgData, batch_size=1, shuffle=False)\nresults = predict(model, test_loader)\nshowResults(path, borders, prediction)",
    "crumbs": [
      "Project",
      "Recognize Handwritten Digits by CNN"
    ]
  },
  {
    "objectID": "posts2/2024-11-16-Recognize-post.html#introduction",
    "href": "posts2/2024-11-16-Recognize-post.html#introduction",
    "title": "Recognize Handwritten Digits by CNN",
    "section": "",
    "text": "A Handwritten Digits Recognition Model based CNN.\n\nBasic Information\n\nNetwork: CNN\nDataset: MNIST\nFramework: Pytorch\nGPU: NVIDIA GTX1070",
    "crumbs": [
      "Project",
      "Recognize Handwritten Digits by CNN"
    ]
  },
  {
    "objectID": "posts2/2024-11-16-Recognize-post.html#download-data",
    "href": "posts2/2024-11-16-Recognize-post.html#download-data",
    "title": "Recognize Handwritten Digits by CNN",
    "section": "",
    "text": "You can download data from MNIST",
    "crumbs": [
      "Project",
      "Recognize Handwritten Digits by CNN"
    ]
  },
  {
    "objectID": "posts2/2024-11-16-Recognize-post.html#code",
    "href": "posts2/2024-11-16-Recognize-post.html#code",
    "title": "Recognize Handwritten Digits by CNN",
    "section": "",
    "text": "Code\nimport cv2\nimport numpy as np\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nimport torch.nn as nn\nimport matplotlib.pyplot as plt\nfrom week_log_1.vgg import CNN\nimport sys\nimport time\nimport scipy.io as scio\nfrom IPython.display import Image, display\n\n\n\n\n\n\n\nCode\n# Reversing the black and white thresholds for each pixel\ndef accessPiexl(img):\n    height = img.shape[0]\n    width = img.shape[1]\n    for i in range(height):\n       for j in range(width):\n           img[i][j] = 255 - img[i][j]\n    return img\n\n# Inverse binarized image\ndef accessBinary(img, threshold=165):\n    img = accessPiexl(img)\n    kernel = np.ones((3, 3), np.uint8)\n    img = cv2.GaussianBlur(img, (3, 3), 0) #Gaussian filter\n    img = cv2.erode(img, kernel, iterations=1) #Border burr removal\n    # adaptive filter\n    img = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 7, -9)\n    img = cv2.dilate(img, kernel, iterations=1)\n    return img\n\n# For showing prediction results\ndef showResults(path, borders, results=None):\n    img = cv2.imread(path)\n    for i, border in enumerate(borders):\n        cv2.rectangle(img, border[0], border[1], (0, 0, 255))\n        if results:\n            cv2.putText(img, str(results[i]), border[0], cv2.FONT_HERSHEY_COMPLEX, 0.8, (0, 255, 0), 1)\n    cv2.waitKey(0)\n    cv2.imwrite('week_log_1/out.jpg',img)\n    display(Image(filename='week_log_1/out.jpg'))\n\n#Search the edge, and return the top right and bottom left coner of the digits\ndef findBorderContours(path, maxArea=1800):\n    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n    img = accessBinary(img)\n    contours, hierarchy = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n    borders = []\n    for contour in contours:\n        #creat a boder\n        x, y, w, h = cv2.boundingRect(contour)\n        if w*h &gt; maxArea:\n            #the coordinate of boder\n            border = [(x, y), (x+w, y+h)]\n            borders.append(border)\n    return borders\n\ndef transUSPS(path, borders, size=(28, 28)):\n    imgData = np.zeros((len(borders), size[0], size[0], 1), dtype='uint8')\n    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n    img = accessBinary(img)\n    for i, border in enumerate(borders):\n        borderImg = img[border[0][1]:border[1][1], border[0][0]:border[1][0]]\n        #Expand pixels based on maximum edge make the border close to square\n        extendPiexl = (max(borderImg.shape) - min(borderImg.shape)) // 2\n        #make border\n        targetImg = cv2.copyMakeBorder(borderImg, 7, 7, extendPiexl + 7, extendPiexl + 7, cv2.BORDER_CONSTANT)\n        targetImg = cv2.resize(targetImg, size)\n        # expand dimension\n        targetImg = np.expand_dims(targetImg, axis=-1)\n        imgData[i] = targetImg\n    return imgData\n# load the model and start predicting!\n\nprediction=[]\ndef predict(modelpath, imgData):\n    model = torch.load(modelpath,weights_only=False)\n    with torch.no_grad():\n        for i, data in enumerate(imgData):\n            data = data.type(torch.FloatTensor)\n            test_pred = model(data.cuda())\n            test_label = np.argmax(test_pred.cpu().data.numpy(), axis=1)\n            for y in test_label:\n                prediction.append(y)\n\n\n\n\n\n\n\nCode\nclass ImgDataset(Dataset):\n    def __init__(self, x, y=None, transform=None):\n        self.x = x\n        # label is required to be a LongTensor\n        self.y = y\n        if y is not None:\n            self.y = torch.LongTensor(y)\n        self.transform = transform\n    def __len__(self):\n        return len(self.x)\n    def __getitem__(self, index):\n        X = self.x[index]\n        if self.transform is not None:\n            X = self.transform(X)\n        if self.y is not None:\n            Y = self.y[index]\n            return X, Y\n        else:\n            return X\n\n\n\n\n\n\n\nCode\nclass Classifier(nn.Module):\n    def __init__(self):\n        super(Classifier, self).__init__()\n        # input dimension [1, 16, 16]\n        self.vgg = nn.Sequential(\n            nn.Conv2d(1, 16, 3, 1, 1),  # [16, 28, 28]\n            nn.BatchNorm2d(16),\n            nn.ReLU(),\n            nn.Conv2d(16, 32, 3, 1, 1),  # [32, 28, 28]\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2),  # [32, 14, 14]\n            nn.Conv2d(32, 64, 3, 1, 1),  # [64, 14, 14]\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.Conv2d(64, 128, 3, 1, 1),  # [128, 14, 14]\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2),  # [128, 7, 7]\n        )\n        #model definition\n        self.fc = nn.Sequential(\n            nn.Linear(128*7*7, 512),\n            nn.ReLU(),\n            nn.Dropout(p=0.5),\n            nn.Linear(512, 1024),\n            nn.ReLU(),\n            nn.Dropout(p=0.5),\n            nn.Linear(1024, 11),\n        )\n#forward propagation\n    def forward(self, x):\n        out = self.vgg(x)\n        out = out.view(out.size()[0], -1)\n        return self.fc(out)\n\n\n\n\n\n\n\nCode\nprint(\"Reading data\")\ndataFile2 = 'week_log_1/vgg/data/MNIST.mat'\ndata2 = scio.loadmat(dataFile2)\n\ntrain = data2['fea']\ntrain=train.reshape(70000,1,28,28)\nlabel = data2['gnd']\ntrain_x = train[:50000]\ntrain_y = label[:50000]\nprint(\"Size of training data = {}\".format(len(train_x)))\nval_x = train[50000:65000]\nval_y = label[50000:65000]\nprint(\"Size of validation data = {}\".format(len(val_x)))\ntest_x = train[65000:68000]\ntest_y = label[65000:68000]\ntest_y=test_y.reshape(3000)\nprint(\"Size of Testing data = {}\".format(len(test_x)))\nprint(\"reading over\")\n\n\nReading data\nSize of training data = 50000\nSize of validation data = 15000\nSize of Testing data = 3000\nreading over\n\n\n\n\n\n\n\nCode\nbatch_size = 500\nif sys.platform.startswith('win'):\n    num_workers = 0  \nelse:\n    num_workers = 4\ntrain_set = ImgDataset(train_x, train_y)\nval_set = ImgDataset(val_x, val_y)\ntrain_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=num_workers)\nval_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, shuffle=False,num_workers=num_workers)\n\ntrain_loss_list=[]\nval_loss_list = []\ntrain_acc_list = []\nval_acc_list = []\n\n#training\nmodel = CNN.Classifier().cuda()\nloss = nn.CrossEntropyLoss()  # loss: CrossEntropyLoss\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # Adam for optimizer\nnum_epoch = 25\nfor epoch in range(num_epoch):\n    epoch_start_time = time.time()\n    train_acc = 0.0\n    train_loss = 0.0\n    val_acc = 0.0\n    val_loss = 0.0\n    model.train()\n    for i, data in enumerate(train_loader):\n        data[0] = data[0].type(torch.FloatTensor)\n        data[1]=data[1].reshape(500)\n        optimizer.zero_grad()  \n        train_pred = model(data[0].cuda())  \n        batch_loss = loss(train_pred, data[1].cuda())  \n        batch_loss.backward()  \n        optimizer.step()  \n        train_acc += np.sum(np.argmax(train_pred.cpu().data.numpy(), axis=1) == data[1].numpy())\n        train_loss += batch_loss.item()\n    model.eval()\n\n    with torch.no_grad():\n        for i, data in enumerate(val_loader):\n            data[0] = data[0].type(torch.FloatTensor)\n            data[1] = data[1].reshape(500)\n            val_pred = model(data[0].cuda())\n            batch_loss = loss(val_pred, data[1].cuda())\n\n            val_acc += np.sum(np.argmax(val_pred.cpu().data.numpy(), axis=1) == data[1].numpy())\n            val_loss += batch_loss.item()\n        if epoch &gt; 20:\n            print('[%03d/%03d] %2.2f sec(s) Train Acc: %3.6f Loss: %3.6f | Val Acc: %3.6f loss: %3.6f' % \\\n              (epoch + 1, num_epoch, time.time() - epoch_start_time, \\\n               train_acc / train_set.__len__(), train_loss / train_set.__len__(), val_acc / val_set.__len__(),\n               val_loss / val_set.__len__()))\n        train_loss_list.append(train_loss / train_set.__len__())\n        val_loss_list.append(val_loss / val_set.__len__())\n        train_acc_list.append(train_acc / train_set.__len__())\n        val_acc_list.append(val_acc / val_set.__len__())\ntorch.save(model,'week_log_1/model.pt')\n\n\n[022/025] 1.42 sec(s) Train Acc: 0.994900 Loss: 0.000032 | Val Acc: 0.992200 loss: 0.000070\n[023/025] 1.42 sec(s) Train Acc: 0.995180 Loss: 0.000032 | Val Acc: 0.991667 loss: 0.000065\n[024/025] 1.42 sec(s) Train Acc: 0.996020 Loss: 0.000028 | Val Acc: 0.991333 loss: 0.000070\n[025/025] 1.43 sec(s) Train Acc: 0.995480 Loss: 0.000030 | Val Acc: 0.990800 loss: 0.000087\n\n\n\n\n\n\nCode\nplt.plot(np.arange(num_epoch),train_loss_list)\nplt.plot(np.arange(num_epoch),val_loss_list)\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.show()\n\nplt.plot(np.arange(num_epoch),train_acc_list)\nplt.plot(np.arange(num_epoch),val_acc_list)\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"accuracy\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\nFigure 1: loss\n\n\n\n\n\n\n\n\n\n\n\nFigure 2: accuracy",
    "crumbs": [
      "Project",
      "Recognize Handwritten Digits by CNN"
    ]
  },
  {
    "objectID": "posts2/2024-11-16-Recognize-post.html#prediction-results",
    "href": "posts2/2024-11-16-Recognize-post.html#prediction-results",
    "title": "Recognize Handwritten Digits by CNN",
    "section": "",
    "text": "Code\npath = 'week_log_1/vgg/data/2.jpg'\nmodel = 'week_log_1/model.pt'\nborders = findBorderContours(path)\n\nimgData = transUSPS(path, borders)\nimgData = np.transpose(imgData,[0,3,1,2])\nimgData = ImgDataset(imgData)\ntest_loader = DataLoader(imgData, batch_size=1, shuffle=False)\nresults = predict(model, test_loader)\nshowResults(path, borders, prediction)",
    "crumbs": [
      "Project",
      "Recognize Handwritten Digits by CNN"
    ]
  },
  {
    "objectID": "posts1/2024-12-14-worklog-post.html",
    "href": "posts1/2024-12-14-worklog-post.html",
    "title": "Week4-5",
    "section": "",
    "text": "1. Missing Semester 2: Shell Tools and Scripting - Exercise 1,2,3\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "WorkLog",
      "Week4",
      "Week4-5"
    ]
  },
  {
    "objectID": "posts1/2024-12-11-worklog-post.html",
    "href": "posts1/2024-12-11-worklog-post.html",
    "title": "Week4-3",
    "section": "",
    "text": "1. About page designed\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "WorkLog",
      "Week4",
      "Week4-3"
    ]
  },
  {
    "objectID": "posts1/2024-12-09-worklog-post.html",
    "href": "posts1/2024-12-09-worklog-post.html",
    "title": "Week4-1",
    "section": "",
    "text": "1. Solving a problem on the website’s top navigation\nExperience: Don’t believe the automatic generation of the navigation\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "WorkLog",
      "Week4",
      "Week4-1"
    ]
  },
  {
    "objectID": "posts1/2024-11-23-worklog-post.html",
    "href": "posts1/2024-11-23-worklog-post.html",
    "title": "Week2",
    "section": "",
    "text": "1. Missing Semester 1: The Shell\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "WorkLog",
      "Week2"
    ]
  },
  {
    "objectID": "posts1/2024-11-16-worklog-post.html",
    "href": "posts1/2024-11-16-worklog-post.html",
    "title": "Week1",
    "section": "",
    "text": "1. A Handwritten Digits Recognition Model based CNN.\n\n\n2. The Birth of My Research Partner LAN 🥳 🥳\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "WorkLog",
      "Week1"
    ]
  },
  {
    "objectID": "posts1/2024-12-07-worklog-post.html",
    "href": "posts1/2024-12-07-worklog-post.html",
    "title": "Week3",
    "section": "",
    "text": "1. The birth of my page\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "WorkLog",
      "Week3"
    ]
  },
  {
    "objectID": "posts1/2024-12-10-worklog-post.html",
    "href": "posts1/2024-12-10-worklog-post.html",
    "title": "Week4-2",
    "section": "",
    "text": "1. A bug in the sidebar repaired\n\n\n2. Design of Home page completed\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "WorkLog",
      "Week4",
      "Week4-2"
    ]
  },
  {
    "objectID": "posts1/2024-12-13-worklog-post.html",
    "href": "posts1/2024-12-13-worklog-post.html",
    "title": "Week4-4",
    "section": "",
    "text": "1. Missing Semester 2: Shell Tools and Scripting\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "WorkLog",
      "Week4",
      "Week4-4"
    ]
  },
  {
    "objectID": "posts1/index.html",
    "href": "posts1/index.html",
    "title": "Work Record",
    "section": "",
    "text": "Week4-5\n\n\n\nWeek Report\n\n\n\n\nWu Hao\n\n\nDec 14, 2024\n\n\n\n\n\n\n\n\n\n\n\nWeek4-4\n\n\n\nWeek Report\n\n\n\n\nWu Hao\n\n\nDec 13, 2024\n\n\n\n\n\n\n\n\n\n\n\nWeek4-3\n\n\n\nWeek Report\n\n\n\n\nWu Hao\n\n\nDec 11, 2024\n\n\n\n\n\n\n\n\n\n\n\nWeek4-1\n\n\n\nWeek Report\n\n\n\n\nWu Hao\n\n\nDec 10, 2024\n\n\n\n\n\n\n\n\n\n\n\nWeek4-2\n\n\n\nWeek Report\n\n\n\n\nWu Hao\n\n\nDec 10, 2024\n\n\n\n\n\n\n\n\n\n\n\nWeek3\n\n\n\nWeek Report\n\n\n\n\nWu Hao\n\n\nDec 7, 2024\n\n\n\n\n\n\n\n\n\n\n\nWeek2\n\n\n\nWeek Report\n\n\n\n\nWu Hao\n\n\nNov 23, 2024\n\n\n\n\n\n\n\n\n\n\n\nWeek1\n\n\n\nWeek Report\n\n\n\n\nWu Hao\n\n\nNov 16, 2024\n\n\n\n\n\n\n\n\nNo matching items\n\n Back to top",
    "crumbs": [
      "WorkLog",
      "Work Record"
    ]
  },
  {
    "objectID": "posts2/index.html",
    "href": "posts2/index.html",
    "title": "Project",
    "section": "",
    "text": "Recognize Handwritten Digits by CNN\n\n\n\nProject\n\n\n\n\nWu Hao\n\n\nNov 16, 2024\n\n\n\n\n\n\n\n\nNo matching items\n\n Back to top",
    "crumbs": [
      "Project"
    ]
  },
  {
    "objectID": "posts/2024-12-12-Missing2-post.html",
    "href": "posts/2024-12-12-Missing2-post.html",
    "title": "Missing Semester 2: Shell Tools and Scripting",
    "section": "",
    "text": "Contents in '(string)' are literal strings\nContents in \"(string)\" are substituted by variable values.\n$ foo=bar\n\n$ echo '$foo'\n$foo\n\n$ echo \"$foo\"\nbar",
    "crumbs": [
      "Blog",
      "Missing-Semester",
      "Shell Tools and Scripting"
    ]
  },
  {
    "objectID": "posts/2024-12-12-Missing2-post.html#assign-variables",
    "href": "posts/2024-12-12-Missing2-post.html#assign-variables",
    "title": "Missing Semester 2: Shell Tools and Scripting",
    "section": "",
    "text": "Contents in '(string)' are literal strings\nContents in \"(string)\" are substituted by variable values.\n$ foo=bar\n\n$ echo '$foo'\n$foo\n\n$ echo \"$foo\"\nbar",
    "crumbs": [
      "Blog",
      "Missing-Semester",
      "Shell Tools and Scripting"
    ]
  },
  {
    "objectID": "posts/2024-12-12-Missing2-post.html#script-function-source-loading-and-execution",
    "href": "posts/2024-12-12-Missing2-post.html#script-function-source-loading-and-execution",
    "title": "Missing Semester 2: Shell Tools and Scripting",
    "section": "Script function, source loading and execution",
    "text": "Script function, source loading and execution\nmcd () {\n     mkdir -p \"$1\"\n     cd \"$1\"\n }\n\n$ source mcd.sh\n\n$ mcd test\nsource executes the commands in the corresponding file.\nmcd test: Create a folder and switch to it.",
    "crumbs": [
      "Blog",
      "Missing-Semester",
      "Shell Tools and Scripting"
    ]
  },
  {
    "objectID": "posts/2024-12-12-Missing2-post.html#bash-arguments",
    "href": "posts/2024-12-12-Missing2-post.html#bash-arguments",
    "title": "Missing Semester 2: Shell Tools and Scripting",
    "section": "Bash arguments",
    "text": "Bash arguments\n$0: Name of the script.\n$1-9: The first through ninth arguments of the function.\n$@: All the arguments\n$#: Number of arguments\n$?: Return code of the previous command\n$ ls\ntest1/  test2/\n\n$ cd test3\n\n# Returns 1 if the previous command failed\n$ echo $?\n1\n\n$ mkdir test3\n\n# Returns 0 if the previous command succeeded\n$ echo $?\n0\n!!: Entire last command.\n$ mkdir /usr/test\nPermission denied\n\n$ sudo !!\nsudo mkdir /usr/test\n$_: Last argument from the last command.\n$ mkdir test3\n\n$ cd $_\n\n$ pwd\n/e/blog/test/test3\n||: or operator; &&: and operator; ;: separate commands\n# A example contains all above command\necho \"Starting program at $(date)\" # Date will be substituted\n\necho \"Running program $0 with $# arguments with pid $$\"\n\nfor file in \"$@\"; do\n    grep foobar \"$file\" &gt; /dev/null 2&gt; /dev/null\n    # When pattern is not found, grep has exit status 1\n    # We redirect STDOUT and STDERR to a null register since we do not care about them\n    if [[ $? -ne 0 ]]; then\n        echo \"File $file does not have any foobar, adding one\"\n        echo \"# foobar\" &gt;&gt; \"$file\"\n    fi\ndone\n\nResults:\n$ ./example.sh mcd.sh test2.sh\nStarting program at 2024年12月13日  16:34:41\nRunning program ./example.sh with 2 arguments with pid 2115\nFile mcd.sh does not have any foobar, adding one\nFile test2.sh does not have any foobar, adding one",
    "crumbs": [
      "Blog",
      "Missing-Semester",
      "Shell Tools and Scripting"
    ]
  },
  {
    "objectID": "posts/2024-12-12-Missing2-post.html#wildcards",
    "href": "posts/2024-12-12-Missing2-post.html#wildcards",
    "title": "Missing Semester 2: Shell Tools and Scripting",
    "section": "Wildcards",
    "text": "Wildcards\n?: Match only one arbitrary character\n*: Match multiple arbitrary characters\n$ ls\nexample.sh  mcd.sh  test/  test1.sh  test2.sh\n\n$ rm test?.sh\n\n$ ls\nexample.sh  mcd.sh  test/\n\n$ ls\nfoo/  test1/  test2/  test3/\n\n$ rmdir tes*\n\n$ ls\nfoo/",
    "crumbs": [
      "Blog",
      "Missing-Semester",
      "Shell Tools and Scripting"
    ]
  },
  {
    "objectID": "posts/2024-12-12-Missing2-post.html#curly-braces",
    "href": "posts/2024-12-12-Missing2-post.html#curly-braces",
    "title": "Missing Semester 2: Shell Tools and Scripting",
    "section": "Curly braces",
    "text": "Curly braces\nWhen you have a series of commands, you can use {} to expand them automatically\n# create two folders: foo/ bar/\n$ mkdir {foo,bar}\n\n# This creates files foo/a, foo/b, ... foo/j, bar/a, bar/b, ... bar/j\n$ touch {foo,bar}/{a..j}",
    "crumbs": [
      "Blog",
      "Missing-Semester",
      "Shell Tools and Scripting"
    ]
  },
  {
    "objectID": "posts/2024-12-12-Missing2-post.html#diff",
    "href": "posts/2024-12-12-Missing2-post.html#diff",
    "title": "Missing Semester 2: Shell Tools and Scripting",
    "section": "diff",
    "text": "diff\ndiff shows differences between 2 files.\n$ touch foo/x bar/y\n\n$ diff &lt;(ls foo) &lt;(ls bar)\n&lt; x\n---\n&gt; y",
    "crumbs": [
      "Blog",
      "Missing-Semester",
      "Shell Tools and Scripting"
    ]
  },
  {
    "objectID": "posts/2024-12-12-Missing2-post.html#redirection",
    "href": "posts/2024-12-12-Missing2-post.html#redirection",
    "title": "Missing Semester 2: Shell Tools and Scripting",
    "section": "Redirection",
    "text": "Redirection\n&lt;: Uses the contents of the file as input to the command.\n$ wc -l &lt; example.sh\n12\n&gt;: Writes the stdout of the command to the specified file (which overwrites the file).\n&gt;&gt;: Writes the stdout of the command to the specified file (without overwriting the file)\n$ echo \"hello\" &gt; test.sh\n\n$ cat test.sh\nhello\n\n$ echo \"world\" &gt;&gt; test.sh\n\n$ cat test.sh\nhello\nworld\n&lt;&lt;: Provides multiple lines of input until matching the specified character.\n$ cat &lt;&lt; EOF\n&gt; This is line 1\n&gt; This is line 2\n&gt; EOF\nThis is line 1\nThis is line 2",
    "crumbs": [
      "Blog",
      "Missing-Semester",
      "Shell Tools and Scripting"
    ]
  },
  {
    "objectID": "posts/2024-12-12-Missing2-post.html#path-environment-variable-for-running-the-script",
    "href": "posts/2024-12-12-Missing2-post.html#path-environment-variable-for-running-the-script",
    "title": "Missing Semester 2: Shell Tools and Scripting",
    "section": "PATH environment variable for running the script",
    "text": "PATH environment variable for running the script\nSearch for the location of the python interpreter in the environment variables by writing #! /usr/bin/env python at the beginning of the script.\n#script.py\n\n#!/usr/bin/env python\nimport sys\nfor arg in reversed(sys.argv[1:]):\n  print(arg)\n\nResults:\n$ ./script.py apple banana cherry\ncherry\nbanana\napple",
    "crumbs": [
      "Blog",
      "Missing-Semester",
      "Shell Tools and Scripting"
    ]
  },
  {
    "objectID": "posts/2024-12-12-Missing2-post.html#finding-files",
    "href": "posts/2024-12-12-Missing2-post.html#finding-files",
    "title": "Missing Semester 2: Shell Tools and Scripting",
    "section": "Finding files",
    "text": "Finding files\n# Find all directories with the name src \n$ find . -name src -type d\n# Find all python files that contain test in their folder paths\n$ find . -path '*/test/*.py' -type f\n# Find all files modified in the last day\n$ find . -mtime -1\n\n$ touch {test1,text2}.txt\n# Delete all files with .tmp extension\n$ find . -name '*.txt' -exec rm {} \\;\n\n$ ls\nexample.sh  mcd.sh  script.py*  test/  test.sh\n.: Search in the current directory, src refer to file name，d refer to type",
    "crumbs": [
      "Blog",
      "Missing-Semester",
      "Shell Tools and Scripting"
    ]
  },
  {
    "objectID": "posts/2024-12-12-Missing2-post.html#finding-code",
    "href": "posts/2024-12-12-Missing2-post.html#finding-code",
    "title": "Missing Semester 2: Shell Tools and Scripting",
    "section": "Finding Code",
    "text": "Finding Code\ngrep Matches patterns from the input text.\n#Searching in a file\n$ grep foobar mcd.sh\n# foobar\n\n# Searching recursively in a folder\n$ grep -R foobar .\n./example.sh:    grep foobar \"$file\" &gt; /dev/null 2&gt; /dev/null\n./example.sh:        echo \"File $file does not have any foobar, adding one\"\n./example.sh:        echo \"# foobar\" &gt;&gt; \"$file\"\n./mcd.sh:# foobar\n\n# Searching and Deleting texts from the input File\n$ grep -v hao@DESKTOP-EUJ3G2* 2024-11-23-Missing1-post.qmd &gt; 2024-11-23-Missing1-post-copy.qmd\nrg searches folders recursively by default",
    "crumbs": [
      "Blog",
      "Missing-Semester",
      "Shell Tools and Scripting"
    ]
  },
  {
    "objectID": "posts/2024-12-12-Missing2-post.html#find-shell-commands",
    "href": "posts/2024-12-12-Missing2-post.html#find-shell-commands",
    "title": "Missing Semester 2: Shell Tools and Scripting",
    "section": "Find shell commands",
    "text": "Find shell commands\nhistory lists the history of commands entered in the shell, and works better with gerp.\nhistory n displays the last n results。\nctrl + R can search the corresponding command from the history",
    "crumbs": [
      "Blog",
      "Missing-Semester",
      "Shell Tools and Scripting"
    ]
  },
  {
    "objectID": "posts/2024-12-12-Missing2-post.html#assignmemt",
    "href": "posts/2024-12-12-Missing2-post.html#assignmemt",
    "title": "Missing Semester 2: Shell Tools and Scripting",
    "section": "Assignmemt",
    "text": "Assignmemt\n\nQuestion 1\nRead man ls and write an ls command that lists files in the following manner.\nIncludes all files, including hidden files; Sizes are listed in human readable format (e.g. 454M instead of 454279954); Files are ordered by recency; Output is colorized;\n\n\nSolution:\n$ ls -lhAtu --color=auto\ntotal 4K\n-rw-r--r-- 1 hao 197609 470 12月 14 23:09 example.sh\n-rw-r--r-- 1 hao 197609  49 12月 14 23:09 mcd.sh\n-rwxr-xr-x 1 hao 197609  81 12月 14 23:09 script.py*\n-rw-r--r-- 1 hao 197609  12 12月 14 23:09 test.sh\ndrwxr-xr-x 1 hao 197609   0 12月 14 23:05 test/\n\n\nQuestion 2\nWrite bash functions marco and polo that do the following. Whenever you execute marco the current working directory should be saved in some manner, then when you execute polo, no matter what directory you are in, polo should cd you back to the directory where you executed marco. For ease of debugging you can write the code in a file marco.sh and (re)load the definitions to your shell by executing source marco.sh.\n\n\nSolution:\n#marco.sh\nmarco() {\n    export MARCO_DIR=\"$(pwd)\"\n    echo \"The current directory is $MARCO_DIR\"\n}\n#polo.sh\npolo() {\n    # if $MARCO_DIR exisits, change the directory (-n checks for non-empty values)\n    if [[ -n \"$MARCO_DIR\" ]]; then\n        cd \"$MARCO_DIR\" || echo \"Failed to change directory\"\n    else \n        echo \"MARCO_DIR is not existed, run marco first\"\n    fi\n}\n# execution\n$ source marco.sh\n\n$ source polo.sh\n\n$ marco\nThe current directory is /e/blog/missing_semester/lecture2\n\n$ cd test\n\n$ polo\n\n$ pwd\n/e/blog/missing_semester/lecture2\n\n\nQuestion 3\nWrite a bash script that runs the following script until it fails and captures its standard output and error streams to files and prints everything at the end.\n# failure.sh\n#!/usr/bin/env bash\n\nn=$(( RANDOM % 100 ))\n\nif [[ n -eq 42 ]]; then\n   echo \"Something went wrong\"\n   &gt;&2 echo \"The error was using magic numbers\"\n   exit 1\nfi\n\necho \"Everything went according to plan\"\n&gt;&2 redirects the output of a command to file descriptor 2, the standard error output (stderr).\n\n\nSolution:\n#check-failure.sh\n#!/usr/bin/env bash\n\nfile=\"failure.sh\"\nsuccess_count=0\n\nwhile true; do\n    ((success_count++))\n    # stdout to run.log, stderr to error.log\n    ./$file &gt;&gt; run.log 2&gt;&gt; error.log\n    if [[ $? -eq 1 ]]; then\n        echo \"The script failed after $success_count runs.\"\n        echo \"Captured standard error:\"\n        cat error.log\n        break\n    fi\ndone\n# execution\n$ source check-failure.sh\nThe script failed after 16 runs.\nCaptured standard error:\nThe error was using magic numbers",
    "crumbs": [
      "Blog",
      "Missing-Semester",
      "Shell Tools and Scripting"
    ]
  }
]